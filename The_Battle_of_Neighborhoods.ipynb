{
    "nbformat_minor": 2, 
    "cells": [
        {
            "source": "<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n\n<h1 align=center><font size = 5>The Battle of the Neighbourhoods</font></h1>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Instructions\n\n\nNow that you have been equipped with the skills and the tools to use location data to explore a geographical location, over the course of two weeks, you will have the opportunity to be as creative as you want and come up with an idea to leverage the Foursquare location data to explore or compare neighborhoods or cities of your choice or to come up with a problem that you can use the Foursquare location data to solve. If you cannot think of an idea or a problem, here are some ideas to get you started:\n\n1. In Module 3, we explored New York City and the city of Toronto and segmented and clustered their neighborhoods. Both cities are very diverse and are the financial capitals of their respective countries. One interesting idea would be to compare the neighborhoods of the two cities and determine how similar or dissimilar they are. Is New York City more like Toronto or Paris or some other multicultural city? I will leave it to you to refine this idea.\n2. In a city of your choice, if someone is looking to open a restaurant, where would you recommend that they open it? Similarly, if a contractor is trying to start their own business, where would you recommend that they setup their office?\n\nThese are just a couple of many ideas and problems that can be solved using location data in addition to other datasets. No matter what you decide to do, make sure to provide sufficient justification of why you think what you want to do or solve is important and why would a client or a group of people be interested in your project.\n\n#### Review criteria\nThis capstone project will be graded by your peers. This capstone project is worth 70% of your total grade. The project will be completed over the course of 2 weeks. Week 1 submissions will be worth 30% whereas week 2 submissions will be worth 40% of your total grade.\n\nFor this week, you will required to submit the following:\n\n1. A description of the problem and a discussion of the background. (15 marks)\n2. A description of the data and how it will be used to solve the problem. (15 marks)\n\nFor the second week, the final deliverables of the project will be:\n\n1. A link to your Notebook on your Github repository, showing your code. (15 marks)\n2. A full report consisting of all of the following components (15 marks):\n - Introduction where you discuss the business problem and who would be interested in this project.\n - Data where you describe the data that will be used to solve the problem and the source of the data.\n - Methodology section which represents the main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, and what machine learnings were used and why.\n - Results section where you discuss the results.\n - Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n - Conclusion section where you conclude the report.\n3. Your choice of a presentation or blogpost. (10 marks)\n\nClearly define a problem or an idea of your choice, where you would need to leverage the Foursquare location data to solve or execute. Remember that data science problems always target an audience and are meant to help a group of stakeholders solve a problem, so make sure that you explicitly describe your audience and why they would care about your problem.\n\nThis submission will eventually become your Introduction/Business Problem section in your final report. So I recommend that you push the report (having your Introduction/Business Problem section only for now) to your Github repository and submit a link to it.\n\nDescribe the data that you will be using to solve the problem or execute your idea. Remember that you will need to use the Foursquare location data to solve the problem or execute your idea. You can absolutely use other datasets in combination with the Foursquare location data. So make sure that you provide adequate explanation and discussion, with examples, of the data that you will be using, even if it is only Foursquare location data.\n\nThis submission will eventually become your Data section in your final report. So I recommend that you push the report (having your Data section) to your Github repository and submit a link to it.\n\n\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n<font size = 3>\n\n1. <a href=\"#item1\">Introduction</a>\n\n2. <a href=\"#item2\">Data</a>\n\n3. <a href=\"#item3\">Methodology</a>\n\n4. <a href=\"#item4\">Results</a>\n\n5. <a href=\"#item5\">Discussion</a>    \n\n6. <a href=\"#item6\">Conclusion</a>    \n</font>\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id='item1'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Introduction/Business Problem (Week 1 & 2)\nA description of the problem and a discussion of the background.  Discuss the business problem and who would be interested in this project.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "NYC is a multi-ethic melting pot. The NYC food scene is vibrant, diverse and constantly changing. Restaurants change with each passing season. For someone new to NYC and homesick, it is difficult to find which neighbourhood will offer cuisine which is closest to home. Hence our target audience are people who are new to NYC and would like to find the neighbourhood with the most familiar food culture compared to their home city, and also help foodies discover new neighbourhood cuisines.\n\nThe code will prompt the user to input their home city and confirm the location visually on a map.  It would then extract the relevant restaurant information from Foursquare, and via K-means clustering, identify the cluster which the home city belongs to and plot the neighbourhoods in the same cluster on the map.  The radius of the plots on the map is the actual area where the restaurant information is extracted from.  This can be changed via the radius setting below.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id='item2'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Data (Week 1 & 2)\nA description of the data and how it will be used to solve the problem.  Describe the data that will be used to solve the problem and the source of the data.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "We plan to leverage on Foursquare restaurant data as well as its menu data to identify neighbourhoods with most similar cuisine as our source city. From the list of neighbourhoods, we would extract the list of well-rated restaurants within a certain promixity to the center of the neighbourhood.  We also extract the same information from the home city.  We would then use that data to identify which NYC neighbourhood cuisine has the greatest similarity with the home city.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<a id='item3'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Methodology (Week 2)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "##### The following user variables can be tweaked.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# set number of clusters.  If no similar neighbourhoods are identified within the same cluster as the home city, you can reduce the cluster size and try again.  \n# Similarly, if too many results are returned, you can instead the cluster size so as to get a better fit.\nkclusters = 50\n\n# radius of foursquare search.  This will apply to both the home city as well as NYC neighbourhoods. \nradius = 750\n\n# limit of foursquare results, max 100\nLIMIT = 100\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Solving environment: - "
                }
            ], 
            "source": "# We first import the necessary libraries\n\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\n#!conda install -c conda-forge beautifulsoup4 --yes\nfrom bs4 import BeautifulSoup # to extract information from websites\n\nimport lxml # library to handle xml parsing\nimport requests # library to handle website requests\n\nfrom pathlib import Path\n\nimport os\n\nprint('Libraries imported.')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Use your own foursquare login details below\nCLIENT_ID = 'xxxx' # your Foursquare ID\nCLIENT_SECRET = 'yyyy' # your Foursquare Secret\nVERSION = '20180605'"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# download dataset\n!wget -q -O 'newyork_data.json' https://cocl.us/new_york_dataset"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# open dataset\nwith open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)# split text into list"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# extract 'features' from dataset\nneighborhoods_data = newyork_data['features']"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# define the dataframe columns\ncolumn_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\nneighborhoods = pd.DataFrame(columns=column_names)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# parse dataset to extract latitude and longitude\nfor data in neighborhoods_data:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    neighborhoods = neighborhoods.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# get NYC latitude and longitude\naddress = 'New York City, NY'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of {} are {}, {}.'.format(address, latitude, longitude))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# prompt user for home city, get latitude and longitude, and plot on map.\n\n# prompt user for home city\ntarget_address = input('Enter city: eg.\"Mumbai, India\"  ')\n\n# get latitude and longitude\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\ntarget_location = geolocator.geocode(target_address)\ntarget_latitude = target_location.latitude\ntarget_longitude = target_location.longitude\nprint('The geograpical coordinate of {} are {}, {}.'.format(target_address, target_latitude, target_longitude))\n\n# create map of Target City using latitude and longitude values\nmap_targetcity = folium.Map(location=[target_latitude, target_longitude], zoom_start=15)\n\n# add markers to map\nlabel = '{}'.format(target_location)\nlabel = folium.Popup(label, parse_html=True)\nfolium.Circle(\n    [target_latitude, target_longitude],\n    radius=radius,\n    popup=label,\n    color='blue',\n    fill=True,\n    fill_color='#3186cc',\n    fill_opacity=0.7,\n    parse_html=False).add_to(map_targetcity)  \n    \nmap_targetcity"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# append home city to list of neighbourhoods\nmanhattan_data = neighborhoods\nmanhattan_data = manhattan_data.append({'Borough':target_address, 'Neighborhood':target_address, 'Latitude':target_latitude, 'Longitude':target_longitude}, ignore_index=True)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define function to extract restaurants from given latitudes, longitudes and radius from Foursqure\ndef getNearbyVenues(names, latitudes, longitudes, radius=radius):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?section=FOOD&client_id={}&client_secret={}&ll={},{}&v={}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            lat, \n            lng, \n            VERSION, \n            radius, \n            LIMIT)\n\n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['categories'][0]['shortName'],\n            v['venue']['id']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue',\n                  'Venue Category',          \n                  'Venue ID']\n    \n    return(nearby_venues)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# get restaurant data for all neighbourhoods from Foursquare\nmanhattan_venues = getNearbyVenues(names=manhattan_data['Neighborhood'],\n                                   latitudes=manhattan_data['Latitude'],\n                                   longitudes=manhattan_data['Longitude']\n                                  )"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# convert restaurant data to one-hot encoding\n\n# one hot encoding\nonehot = pd.get_dummies(manhattan_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nonehot['Neighborhood'] = manhattan_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [onehot.columns[-1]] + list(onehot.columns[:-1])\nonehot = onehot[fixed_columns]\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# reset index\nmanhattan_grouped = onehot.groupby('Neighborhood').mean().reset_index()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define function to return most common restaurants\ndef return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# show top 10 most common restaurants for each neighbourhood\nnum_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = manhattan_grouped['Neighborhood']\n\nfor ind in np.arange(manhattan_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(manhattan_grouped.iloc[ind, :], num_top_venues)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# use K-Means clustering to cluster neighbourhoods based on 10 most common restaurants \nmanhattan_grouped_clustering = manhattan_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(manhattan_grouped_clustering)\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nmanhattan_merged = manhattan_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nmanhattan_merged = manhattan_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# add location data to the clustered data\nCluster = manhattan_merged.loc[manhattan_merged['Borough'] == target_address, 'Cluster Labels'].iloc[0]\n\nmanhattan_merged = manhattan_merged.drop(manhattan_merged[manhattan_merged['Cluster Labels'] != Cluster].index)\n"
        }, 
        {
            "source": "<a id='item4'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Results (Week 2)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters+1)\nys = [i + x + (i*x)**2 for i in range(kclusters+1)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(manhattan_merged['Latitude'], manhattan_merged['Longitude'], manhattan_merged['Neighborhood'], manhattan_merged['Cluster Labels']):\n\n    # no data from help so all the NaN neighbourhoods will be allocated to cluster 6\n    if cluster != cluster:\n        cluster = 6\n    else: cluster = int(cluster)\n    \n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.Circle(\n        [lat, lon],\n        radius=radius,\n        height=800,\n        width=600,\n        popup=label,\n        #color=rainbow[cluster-1],\n        color='red',\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# show list of neighbourhoods in the same cluster as the home city\nmanhattan_merged.loc[manhattan_merged['Cluster Labels'] == Cluster, manhattan_merged.columns[[1] + list(range(5, manhattan_merged.shape[1]))]]"
        }, 
        {
            "source": "<a id='item5'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Discussion (Week 2)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "source": "<a id='item6'></a>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Conclusion (Week 2)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "source": "### Thank you for completing this lab!\n\nThis notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/) and [Polong Lin](https://www.linkedin.com/in/polonglin/). I hope you found this lab interesting and educational. Feel free to contact us if you have any questions!", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "This notebook is part of a course on **Coursera** called *Applied Data Science Capstone*. If you accessed this notebook outside the course, you can take this course online by clicking [here](http://cocl.us/DP0701EN_Coursera_Week3_LAB2).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<hr>\n\nCopyright &copy; 2018 [Cognitive Class](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "widgets": {
            "state": {}, 
            "version": "1.1.2"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}